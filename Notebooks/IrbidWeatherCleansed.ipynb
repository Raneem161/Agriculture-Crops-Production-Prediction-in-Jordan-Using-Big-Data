{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jKUmtqX8Jl3L"
   },
   "source": [
    "# Irbid weather data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zfmJUcP1JzLx"
   },
   "source": [
    "This notebook will cleanse, visualize and explore weather data for Irbid city obtained from ArabiaWeather. For further details please check the technical documentation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "ODL1E6H-ao9c"
   },
   "outputs": [],
   "source": [
    "# To measure the loading time\n",
    "import time\n",
    "\n",
    "start_time = time.time()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NhHdmW9OQoZb"
   },
   "source": [
    "# Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uo0U0o1-PTPw",
    "outputId": "ff33534f-f76c-4c6a-b64e-d00cf3da654d"
   },
   "outputs": [],
   "source": [
    "# Install pyspark because weather data is big data and we need pyspark to deal with it\n",
    "!pip install pyspark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "CzzbLrMsPwWr"
   },
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType,StructField, IntegerType, FloatType, StringType, DateType\n",
    "\n",
    "# In this colab we didn't use cluster we used single machine local[*].\n",
    "# However, if we want change it to cluster, we can change it to master url 7077\n",
    "spark =  SparkSession.builder.appName(\"SparkApp\").master(\"local[*]\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "EQRu5VPUP_r0"
   },
   "outputs": [],
   "source": [
    "# Importing the irbid weather dataset\n",
    "WEATHER_IRBID = \"Irbid.csv\"\n",
    "\n",
    "# Using our own schema to define datatypes of the dataset features\n",
    "Myschema = StructType([\n",
    "StructField('Station', StringType(),True),\n",
    "StructField('Date/Time', DateType(),True),\n",
    "StructField('Air Dew Point', IntegerType(),True),\n",
    "StructField('Air Temperature (OC)', IntegerType(),True),\n",
    "StructField('Humidity %', IntegerType(),True),\n",
    "StructField('Manual Present Weather', StringType(),True),\n",
    "StructField('Cloud Type', StringType(),True),\n",
    "StructField('Clouds Cover (Okta)', IntegerType(),True),\n",
    "StructField('Cloud Cover %', IntegerType(),True),\n",
    "StructField('Wind Direction (Degrees)', IntegerType(),True),\n",
    "StructField('Wind Speed (MPS)', IntegerType(),True),\n",
    "StructField('Wind Type', StringType(),True)])\n",
    "\n",
    "# Reading the data in df\n",
    "df = spark.read.csv(WEATHER_IRBID,header=True, schema=Myschema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cv4CzZqkQSUg",
    "outputId": "cb3fc18a-d776-4b84-f2ce-1442e1cbf8e4"
   },
   "outputs": [],
   "source": [
    "# Show the df\n",
    "df.show(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W-Tg18f1QZLp",
    "outputId": "9648cac2-73e1-45d5-8b03-a0bf53c7650b"
   },
   "outputs": [],
   "source": [
    "# Show summary statistics\n",
    "df.describe().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "c65YXcLgQsML"
   },
   "source": [
    "# Handling missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R84UxEnyQlcu",
    "outputId": "7f0ce70b-391f-4241-ca02-6a6de93f968f"
   },
   "outputs": [],
   "source": [
    "# Showing the null values' count\n",
    "from pyspark.sql.functions import *\n",
    "col_null_cnt_df =  df.select([count(when(col(c).isNull(),c)).alias(c) for c in df.columns])\n",
    "col_null_cnt_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "l2ypx-80Q5n_"
   },
   "outputs": [],
   "source": [
    "# Dropping features with high percentage of nulls and will not affect the agriculture highly\n",
    "df = df.drop('Air Dew Point') # --> can be known from humidity\n",
    "df = df.drop('Manual Present Weather') # --> the general weather, can be known from other features\n",
    "df = df.drop('Cloud Type') # --> type doesn't affect production\n",
    "df = df.drop('Clouds Cover (Okta)') # --> we have cloud cover in %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ER3EOYtVRcuA"
   },
   "outputs": [],
   "source": [
    "# Drop all rows where any value at specific columns are NAs, because its not a big number of rows\n",
    "df = df.na.drop(how='any', subset=['Air Temperature (OC)','Cloud Cover %', 'Wind Speed (MPS)', 'Wind Type']) # 'any' is the defult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QcqPfT8uRoQ1",
    "outputId": "b66c10ae-6cf9-45c3-8a94-5b9b0939d9f1"
   },
   "outputs": [],
   "source": [
    "# Using the window technique to fill the null values in the wind direction column using the last non-null value within the window.\n",
    "\n",
    "from pyspark.sql.functions import col, last\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "target_column = \"Wind Direction (Degrees)\"\n",
    "\n",
    "# Sorting the DataFrame by the date column in ascending order\n",
    "sorted_df = df.orderBy(\"Date/Time\")\n",
    "\n",
    "# Creating a window specification based on the date column\n",
    "window_spec = Window.orderBy(\"Date/Time\").rowsBetween(Window.unboundedPreceding, 0)\n",
    "\n",
    "# Filling null values in the target column using the last non-null value\n",
    "df = sorted_df.withColumn(target_column, last(col(target_column), ignorenulls=True).over(window_spec))\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FVQQoia2SAe0"
   },
   "outputs": [],
   "source": [
    "# Drop all rows where any value at specific columns are NAs, for any rows that didn't have a non vull value before them\n",
    "df = df.na.drop(how='any', subset=['Wind Direction (Degrees)']) # 'any' is the defult"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KDsK7iioSKlg",
    "outputId": "56c5869c-6f45-4d40-8578-67b8d76fa292"
   },
   "outputs": [],
   "source": [
    "# Show the nulls again\n",
    "from pyspark.sql.functions import *\n",
    "col_null_cnt_df =  df.select([count(when(col(c).isNull(),c)).alias(c) for c in df.columns])\n",
    "col_null_cnt_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f6Ax-21BSRRN"
   },
   "outputs": [],
   "source": [
    "# Using linear regression to create a formula that predicts the humidity from other features\n",
    "\n",
    "from pyspark.sql.functions import col, isnan\n",
    "from pyspark.ml.feature import StringIndexer, VectorAssembler\n",
    "from pyspark.ml.regression import LinearRegression\n",
    "\n",
    "# Filter out rows with null or NaN values in the Humidity column\n",
    "data = df.filter(col(\"Humidity %\").isNotNull() & ~isnan(\"Humidity %\"))\n",
    "\n",
    "# Create StringIndexer to convert the Station column into numerical labels\n",
    "station_indexer = StringIndexer(inputCol=\"Station\", outputCol=\"Station_Index\")\n",
    "data = station_indexer.fit(data).transform(data)\n",
    "\n",
    "# Create StringIndexer to convert the Wind Type column into numerical labels\n",
    "wind_type_indexer = StringIndexer(inputCol=\"Wind Type\", outputCol=\"Wind_Type_Index\")\n",
    "data = wind_type_indexer.fit(data).transform(data)\n",
    "\n",
    "# Include the Station_Index and Wind_Type_Index columns in the VectorAssembler\n",
    "assembler = VectorAssembler(inputCols=[\"Air Temperature (OC)\", \"Cloud Cover %\", \"Wind Direction (Degrees)\", \"Wind Speed (MPS)\"],\n",
    "                            outputCol=\"features\")\n",
    "data = assembler.transform(data)\n",
    "\n",
    "# Select the relevant columns for the linear regression model\n",
    "selected_data = data.select(\"features\", \"Humidity %\")\n",
    "\n",
    "# Split the data into training and test sets\n",
    "train_data, test_data = selected_data.randomSplit([0.8, 0.2], seed=42)\n",
    "\n",
    "# Create and fit the linear regression model\n",
    "lr = LinearRegression(featuresCol=\"features\", labelCol=\"Humidity %\")\n",
    "model = lr.fit(train_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yo_JCVNGS8-Z",
    "outputId": "d7f35406-642f-438a-ccd8-0d5e951afa27"
   },
   "outputs": [],
   "source": [
    "from pyspark.ml.evaluation import RegressionEvaluator\n",
    "\n",
    "predictions = model.transform(test_data)\n",
    "\n",
    "# Evaluate the model using R-squared\n",
    "evaluator = RegressionEvaluator(labelCol=\"Humidity %\", predictionCol=\"prediction\", metricName=\"r2\")\n",
    "r2 = evaluator.evaluate(predictions)\n",
    "\n",
    "print(\"R-squared:\", r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gLIwDNB8TYIO",
    "outputId": "f3de914c-2b4a-491e-d62e-21b8abf9dc29"
   },
   "outputs": [],
   "source": [
    "# Getting the formula's intercept and coefficients\n",
    "coefficients = model.coefficients\n",
    "intercept = model.intercept\n",
    "\n",
    "print(coefficients)\n",
    "print(intercept)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uxStxnpITgwq",
    "outputId": "29bed7e5-9fef-46cd-b0c1-8b6843a9e876"
   },
   "outputs": [],
   "source": [
    "# Filling nulls in the humidity column with the predections from the formula\n",
    "\n",
    "from pyspark.sql.functions import col, when\n",
    "\n",
    "# Define the equation coefficients and intercept\n",
    "coefficients = [-1.6125718631802315,0.14974536899814145,0.1012784149968023,-1.3526705169477602]\n",
    "intercept = 55.77390283264818\n",
    "\n",
    "# Fill null values in the \"Humidity %\" column using the equation\n",
    "df = df.withColumn(\"Humidity %\", when(col(\"Humidity %\").isNull(),\n",
    "                                      intercept + (coefficients[0] * col(\"Air Temperature (OC)\")) +\n",
    "                                      (coefficients[1] * col(\"Cloud Cover %\")) +\n",
    "                                      (coefficients[1] * col(\"Wind Direction (Degrees)\")) +\n",
    "                                      (coefficients[3] * col(\"Wind Speed (MPS)\")))\n",
    "                               .otherwise(col(\"Humidity %\")))\n",
    "\n",
    "# Show the updated DataFrame\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sm9hnnj5UVHl",
    "outputId": "d56ee9a7-cb51-4f67-ac75-1fbdd8aea3fc"
   },
   "outputs": [],
   "source": [
    "# Checking the null count for the last time\n",
    "from pyspark.sql.functions import *\n",
    "col_null_cnt_df =  df.select([count(when(col(c).isNull(),c)).alias(c) for c in df.columns])\n",
    "col_null_cnt_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VVWLjjn4Ucub",
    "outputId": "6bfc50cc-caec-4043-fd54-029991e6f667"
   },
   "outputs": [],
   "source": [
    "# Checking the data count\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8nZeQJW2UlEc"
   },
   "source": [
    "# EDA and visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "_XzuZAT3UnnY",
    "outputId": "3501428c-6994-41ae-b729-fbfddf13ee20"
   },
   "outputs": [],
   "source": [
    "# Plotting the general weather among years\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "\n",
    "features = [\"Station\", \"Date/Time\", \"Air Temperature (OC)\", \"Humidity %\", \"Cloud Cover %\", \"Wind Direction (Degrees)\", \"Wind Speed (MPS)\", \"Wind Type\"]\n",
    "\n",
    "for feature in features:\n",
    "    data = df.select('Date/Time', feature).toPandas()\n",
    "\n",
    "    # Create a Plotly figure\n",
    "    fig = go.Figure()\n",
    "\n",
    "    # Add a scatter trace for the feature\n",
    "    fig.add_trace(go.Scatter(x=data['Date/Time'], y=data[feature], mode='lines', name=feature))\n",
    "\n",
    "    # Set the layout\n",
    "    fig.update_layout(title=feature + ' Trends', xaxis_title='Date/Time', yaxis_title=feature)\n",
    "\n",
    "    # Show the plot\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vf5_2x4NVR6j"
   },
   "outputs": [],
   "source": [
    "# Dropping features that will not assess the prediction of agriculture production according to the subject matter expert\n",
    "df = df.drop('Wind Type')\n",
    "df = df.drop('Cloud Cover %')\n",
    "df = df.drop('Wind Direction (Degrees)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "NVwd88j7VeXE",
    "outputId": "e7ac089e-b63c-4001-8f6b-f998bfcd3b7e"
   },
   "outputs": [],
   "source": [
    "# Shwoing the df\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "jwdvmtVaV8sU",
    "outputId": "a1da513c-9f9e-4fed-e87d-7ab2e3f9877d"
   },
   "outputs": [],
   "source": [
    "# Plotting the temperature for months amongst years\n",
    "\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "# Convert the DataFrame to Pandas for easier manipulation\n",
    "data_pd = df.toPandas()\n",
    "\n",
    "# Extract the year and month from the Date/Time column\n",
    "data_pd['Year'] = pd.to_datetime(data_pd['Date/Time']).dt.year\n",
    "data_pd['Month'] = pd.to_datetime(data_pd['Date/Time']).dt.month\n",
    "\n",
    "# Group the data by Year and Month and calculate the average temperature\n",
    "average_temp = data_pd.groupby(['Year', 'Month'])['Air Temperature (OC)'].mean().reset_index()\n",
    "\n",
    "# Create separate plots for each year\n",
    "for year in average_temp['Year'].unique():\n",
    "    year_data = average_temp[average_temp['Year'] == year]\n",
    "\n",
    "    # Create the plot using Plotly Express\n",
    "    fig = px.line(year_data, x='Month', y='Air Temperature (OC)')\n",
    "\n",
    "    # Set the layout\n",
    "    fig.update_layout(title=f'Average Air Temperature by Month - {year}',\n",
    "                      xaxis_title='Month',\n",
    "                      yaxis_title='Air Temperature (OC)')\n",
    "\n",
    "    # Show the plot\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "gnl5OJRXXP_M",
    "outputId": "37399072-4675-433f-8c4e-64df9927f135"
   },
   "outputs": [],
   "source": [
    "# Plotting the humidity for months amongst years\n",
    "\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "# Convert the DataFrame to Pandas for easier manipulation\n",
    "data_pd = df.toPandas()\n",
    "\n",
    "# Extract the year and month from the Date/Time column\n",
    "data_pd['Year'] = pd.to_datetime(data_pd['Date/Time']).dt.year\n",
    "data_pd['Month'] = pd.to_datetime(data_pd['Date/Time']).dt.month\n",
    "\n",
    "# Group the data by Year and Month and calculate the average humidity\n",
    "average_humidity = data_pd.groupby(['Year', 'Month'])['Humidity %'].mean().reset_index()\n",
    "\n",
    "# Iterate over each unique year\n",
    "for year in average_humidity['Year'].unique():\n",
    "    year_data = average_humidity[average_humidity['Year'] == year]\n",
    "\n",
    "    # Create the plot using Plotly Express\n",
    "    fig = px.line(year_data, x='Month', y='Humidity %')\n",
    "\n",
    "    # Set the layout\n",
    "    fig.update_layout(title=f'Average Humidity by Month - {year}',\n",
    "                      xaxis_title='Month',\n",
    "                      yaxis_title='Humidity %')\n",
    "\n",
    "    # Show the plot\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "am47zCPnX1wn",
    "outputId": "38000446-a4d5-4fbf-f53c-0124c4d9d770"
   },
   "outputs": [],
   "source": [
    "# Plotting the wind speed for months amongst years\n",
    "\n",
    "import plotly.express as px\n",
    "import pandas as pd\n",
    "\n",
    "# Convert the DataFrame to Pandas for easier manipulation\n",
    "data_pd = df.toPandas()\n",
    "\n",
    "# Extract the year and month from the Date/Time column\n",
    "data_pd['Year'] = pd.to_datetime(data_pd['Date/Time']).dt.year\n",
    "data_pd['Month'] = pd.to_datetime(data_pd['Date/Time']).dt.month\n",
    "\n",
    "# Group the data by Year and Month and calculate the average wind speed\n",
    "average_wind_speed = data_pd.groupby(['Year', 'Month'])['Wind Speed (MPS)'].mean().reset_index()\n",
    "\n",
    "# Iterate over each unique year\n",
    "for year in average_wind_speed['Year'].unique():\n",
    "    year_data = average_wind_speed[average_wind_speed['Year'] == year]\n",
    "\n",
    "    # Create the plot using Plotly Express\n",
    "    fig = px.line(year_data, x='Month', y='Wind Speed (MPS)')\n",
    "\n",
    "    # Set the layout\n",
    "    fig.update_layout(title=f'Average Wind Speed by Month - {year}',\n",
    "                      xaxis_title='Month',\n",
    "                      yaxis_title='Wind Speed (MPS)')\n",
    "\n",
    "    # Show the plot\n",
    "    fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "VXWIQtTuYKmA",
    "outputId": "93720cc8-f3b8-4642-bd65-b14c9a2b72e5"
   },
   "outputs": [],
   "source": [
    "# Plotting the temperature and humidity over time\n",
    "\n",
    "import pandas as pd\n",
    "import plotly.graph_objects as go\n",
    "\n",
    "# Convert the Spark DataFrame to Pandas DataFrame\n",
    "df_pandas = df.toPandas()\n",
    "\n",
    "# Line Plot: Temperature and Humidity Over Time\n",
    "fig = go.Figure()\n",
    "fig.add_trace(go.Scatter(x=df_pandas['Date/Time'], y=df_pandas['Air Temperature (OC)'], name='Temperature'))\n",
    "fig.add_trace(go.Scatter(x=df_pandas['Date/Time'], y=df_pandas['Humidity %'], name='Humidity'))\n",
    "fig.update_layout(title='Temperature and Humidity Over Time', xaxis_title='Date/Time', yaxis_title='Value')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 0
    },
    "id": "_adkh7WDY7BH",
    "outputId": "ab2baba9-d73e-4278-8fd6-af330f7fcbc3"
   },
   "outputs": [],
   "source": [
    "# Plotting the distribution of temperature by month\n",
    "df_pandas['Month'] = pd.to_datetime(df_pandas['Date/Time']).dt.month\n",
    "fig = px.box(df_pandas, x='Month', y='Air Temperature (OC)', title='Distribution of Temperature by Month')\n",
    "fig.update_layout(xaxis_title='Month', yaxis_title='Temperature (OC)')\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_cT76ZbSZc-m"
   },
   "source": [
    "# Data transformation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "y2GQ8iv7Zfh4",
    "outputId": "ed2f2d56-ee15-4e95-93b4-b4c3f67ce98a"
   },
   "outputs": [],
   "source": [
    "# Aggregate hours of each day to days based on the mean value (to include the effect of night times)\n",
    "\n",
    "from pyspark.sql.functions import mean\n",
    "from pyspark.sql.functions import to_date\n",
    "\n",
    "df = df.withColumn(\"Date\", to_date(df[\"Date/Time\"]))\n",
    "\n",
    "df = df.groupBy(\"Date\").agg(\n",
    "    mean(\"Air Temperature (OC)\").alias(\"Mean Air Temperature\"),\n",
    "    mean(\"Humidity %\").alias(\"Mean Humidity\"),\n",
    "    mean(\"Wind Speed (MPS)\").alias(\"Mean Wind Speed\")\n",
    ")\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "86OCKwVGaBIz",
    "outputId": "79b5a1f7-c44d-451f-d7d3-998f6a97c768"
   },
   "outputs": [],
   "source": [
    "# Check the count after aggregation\n",
    "df.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "czg3RTFPacp0",
    "outputId": "be211b19-26f0-4789-b085-d743bb81adfa"
   },
   "outputs": [],
   "source": [
    "# General weather among days again\n",
    "import plotly.express as px\n",
    "\n",
    "# Convert the PySpark DataFrame to a Pandas DataFrame\n",
    "pandas_df = df.select(\"*\").toPandas()\n",
    "\n",
    "# Plotting the data using Plotly\n",
    "fig = px.line(pandas_df, x=\"Date\", y=[\"Mean Air Temperature\", \"Mean Humidity\", \"Mean Wind Speed\"],\n",
    "              labels={\"value\": \"Value\"}, title=\"Mean Measures\")\n",
    "fig.update_layout(xaxis_tickangle=-45)\n",
    "fig.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "O-NbjMpgNyqe"
   },
   "outputs": [],
   "source": [
    "# Mean wind speed will also be dropped as its nearly not changing so it won't affect production\n",
    "df = df.drop(\"Mean Wind Speed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "T1CgxJ4XO4p0",
    "outputId": "5ec48b92-298c-4d8b-b169-ee250a0fae0e"
   },
   "outputs": [],
   "source": [
    "# Split months to summer and winter for irbid\n",
    "\n",
    "from pyspark.sql.functions import col, when, year, count\n",
    "\n",
    "# Convert the \"Date\" column to a date type\n",
    "df = df.withColumn(\"Date\", col(\"Date\").cast(\"date\"))\n",
    "\n",
    "# Define the conditions for winter and summer seasons\n",
    "winter_condition = (month(col(\"Date\")).between(11, 12)) | (month(col(\"Date\")).between(1, 5))\n",
    "summer_condition = ~(winter_condition)\n",
    "\n",
    "# Create new column \"Season\" based on the defined conditions\n",
    "df = df.withColumn(\"Season\", when(winter_condition, \"Winter\").otherwise(\"Summer\"))\n",
    "\n",
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "owu92VsHaxmc"
   },
   "outputs": [],
   "source": [
    "# Save the DataFrame as a CSV file to use with production data\n",
    "df.write.csv('/content/Irbid_Cleansed_final.csv', header=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wIIEjdoCaxAR"
   },
   "source": [
    "# Measuring Loading Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LYwm7GMGa881",
    "outputId": "aac0825c-0cab-4926-ee0c-74c2e56b92b2"
   },
   "outputs": [],
   "source": [
    "end_time = time.time()\n",
    "\n",
    "loading_time = end_time - start_time\n",
    "print(\"Loading Time:\", loading_time, \"seconds\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3bDUwf0Qa0Nq"
   },
   "source": [
    "# Measuring Computing resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "H9CVpI6Va2sW",
    "outputId": "bb1d5405-9a06-4614-e89c-6844e9f4a6da"
   },
   "outputs": [],
   "source": [
    "!pip install psutil\n",
    "\n",
    "import psutil\n",
    "\n",
    "cpu_usage = psutil.cpu_percent()\n",
    "ram_usage = psutil.virtual_memory().percent\n",
    "\n",
    "print(\"CPU Usage:\", cpu_usage, \"%\")\n",
    "print(\"RAM Usage:\", ram_usage, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AkyqILooa6S7"
   },
   "source": [
    "# Measuring Storage resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VGWlJoC8a8j1",
    "outputId": "cfae6a2c-709e-46f3-8565-f96ac23501d5"
   },
   "outputs": [],
   "source": [
    "!df -h"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "NhHdmW9OQoZb",
    "c65YXcLgQsML",
    "8nZeQJW2UlEc",
    "_cT76ZbSZc-m"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
